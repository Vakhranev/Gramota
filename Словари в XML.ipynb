{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGWAU/Iyi5AZJUXQftckC1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vakhranev/Gramota/blob/main/%D0%A1%D0%BB%D0%BE%D0%B2%D0%B0%D1%80%D0%B8%20%D0%B2%20XML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "tmjZHZZUOT_2"
      },
      "outputs": [],
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import re\n",
        "\n",
        "# Список сокращений\n",
        "abbreviations = set([\n",
        "    \"адыг.\", \"америк.\", \"англ.\", \"арабск.\", \"арамейск.\", \"ассир.\", \"атт.\", \"баскск.\", \"библ.\",\n",
        "    \"болг.\", \"букв.\", \"валлийск.\", \"венг.\", \"вост.\", \"в-т\", \"галльск.\", \"гаек.\", \"гаэльск.\", \"герм.\",\n",
        "    \"гот.\", \"греч.\", \"груз.\", \"дагест.\", \"дат.\", \"диал.\", \"др.\", \"евр.\", \"егип.\", \"ж.\", \"зап.\", \"им.\",\n",
        "    \"ирл.\", \"исл.\", \"исп.\", \"ит.\", \"кавк.\", \"карфагенск.\", \"кельт.\", \"коптск.\", \"корейск.\", \"коре.\",\n",
        "    \"кумык.\", \"ласк.\", \"лат.\", \"лит.\", \"м.\", \"марийск.\", \"н.\", \"нар.\", \"нем.\", \"нидерл.\", \"нов.\",\n",
        "    \"норв.\", \"норм.\", \"орф.\", \"осет.\", \"перс.\", \"пожелат.\", \"половецк.\", \"польск.\", \"порт.\", \"прил.\",\n",
        "    \"прованс.\", \"разг.\", \"римск.\", \"румынск.\", \"рус.\", \"савойск.\", \"санскр.\", \"сербск.\", \"сирийск.\",\n",
        "    \"сканд.\", \"слав.\", \"см.\", \"сокр.\", \"ср.\", \"стар.\", \"тат.\", \"традиц.\", \"тур.\", \"тюрк.\", \"укр.\",\n",
        "    \"уменьш.\", \"усеч.\", \"ф.\", \"финск.\", \"флам.\", \"фракийск.\", \"фр.\", \"фриз.\", \"халдейск.\", \"церк.\",\n",
        "    \"цыг.\", \"чешек.\", \"швед.\", \"шотл.\", \"эльз.\", \"эолийск.\", \"др.-евр.\"\n",
        "])\n",
        "\n",
        "# Функция обработки XML\n",
        "def process_xml(input_file, output_file):\n",
        "    tree = ET.parse(input_file)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    page_number = 1\n",
        "    new_pages = []\n",
        "\n",
        "    for page in root.findall('.//page'):\n",
        "        new_page = ET.Element('page', {'number': str(page_number)})\n",
        "        page_number += 1\n",
        "\n",
        "        paragraphs = [p.text.strip() for p in page.findall('.//paragraph') if p.text]\n",
        "        text = \" \".join(paragraphs)\n",
        "\n",
        "        if text == \"ЖЕНСКИЕ ИМЕНА\":\n",
        "            new_page.append(ET.Element('female_names'))\n",
        "            new_page[-1].text = text\n",
        "            new_pages.append(new_page)\n",
        "            continue\n",
        "        elif text == \"МУЖСКИЕ ИМЕНА\":\n",
        "            new_page.append(ET.Element('male_names'))\n",
        "            new_page[-1].text = text\n",
        "            new_pages.append(new_page)\n",
        "            continue\n",
        "\n",
        "        words = text.split()\n",
        "        i = 0\n",
        "\n",
        "        while i < len(words):\n",
        "            if words[i][0].isupper():\n",
        "                word = words[i]\n",
        "                i += 1\n",
        "\n",
        "                definition_words = []\n",
        "                open_square_brackets = 0\n",
        "                open_parentheses = 0\n",
        "\n",
        "                while i < len(words):\n",
        "                    definition_words.append(words[i])\n",
        "\n",
        "                    # Проверка на открытые скобки\n",
        "                    open_square_brackets += words[i].count('[')\n",
        "                    open_square_brackets -= words[i].count(']')\n",
        "\n",
        "                    # Если встречаем точку, проверяем завершение\n",
        "                    if words[i][-1] == '.':\n",
        "                        # Проверка на сокращения\n",
        "                        if words[i] not in abbreviations and open_square_brackets == 0 and open_parentheses == 0:\n",
        "                            # Проверка следующего слова\n",
        "                            if i + 1 < len(words) and words[i + 1][0].isupper():\n",
        "                                # Если следующее слово с большой буквы, то завершение\n",
        "                                break\n",
        "                    i += 1\n",
        "\n",
        "                # Собираем определение и добавляем его в запись\n",
        "                definition = \" \".join(definition_words).strip()\n",
        "\n",
        "                entry = ET.Element('entry')\n",
        "                word_elem = ET.SubElement(entry, 'word')\n",
        "                word_elem.text = word.rstrip(',')\n",
        "                def_elem = ET.SubElement(entry, 'definition')\n",
        "                def_elem.text = definition\n",
        "                new_page.append(entry)\n",
        "\n",
        "            i += 1\n",
        "\n",
        "        new_pages.append(new_page)\n",
        "\n",
        "    root.clear()\n",
        "    for new_page in new_pages:\n",
        "        root.append(new_page)\n",
        "\n",
        "    tree.write(output_file, encoding=\"utf-8\", xml_declaration=True)\n",
        "\n",
        "# Входной и выходной файлы\n",
        "input_file = 'Superanskaya_Slovar_russkikh_lichnykh_imyon.xml'\n",
        "output_file = 'processed_Slovar.xml'\n",
        "\n",
        "# Запуск обработки\n",
        "process_xml(input_file, output_file)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import re\n",
        "\n",
        "def is_cyrillic(word):\n",
        "    # Убираем точку в конце, если есть\n",
        "    word = word.rstrip('.')\n",
        "\n",
        "    # Проверяем, состоит ли слово из заглавных кириллических букв и (cid:141), причем оно должно быть длиннее одной буквы\n",
        "    return re.fullmatch(r'(?:[А-ЯЁ]+(?:\\(cid:141\\))?)+', word) is not None and len(word) > 1\n",
        "\n",
        "def contains_vowel(word):\n",
        "    # Проверяем, есть ли в слове хотя бы одна гласная (А, Е, Ё, И, О, У, Ы, Э, Ю, Я)\n",
        "    vowels = \"АЕЁИОУЫЭЮЯ\"\n",
        "    return sum(1 for char in word if char in vowels)\n",
        "\n",
        "def process_xml(input_file, output_file):\n",
        "    tree = ET.parse(input_file)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    new_root = ET.Element(\"document\")\n",
        "    page_number = 0\n",
        "    skip_next = False\n",
        "    current_entry = None\n",
        "    collecting_definition = False  # Флаг, показывающий, собираем ли мы текст для definition\n",
        "\n",
        "    for paragraph in root.findall(\".//paragraph\"):\n",
        "        text = paragraph.text.strip() if paragraph.text else \"\"\n",
        "\n",
        "        # Проверяем, является ли paragraph номером страницы\n",
        "        if text.isdigit():\n",
        "            page_number += 1\n",
        "            skip_next = True  # Устанавливаем флаг, чтобы пропустить следующий paragraph\n",
        "            continue\n",
        "\n",
        "        if skip_next:\n",
        "            skip_next = False\n",
        "            continue  # Пропускаем этот paragraph\n",
        "\n",
        "        # Пропускаем параграфы, содержащие только одну букву\n",
        "        if len(text) == 1:\n",
        "            continue\n",
        "\n",
        "        words = text.split()\n",
        "\n",
        "        # Проверяем, если в paragraph только одно слово\n",
        "        if len(words) == 1:\n",
        "            word = words[0]\n",
        "\n",
        "            # Проверяем, что слово написано в верхнем регистре, без \"(cid:141)\" и с более чем одной гласной\n",
        "            if word.isupper() and contains_vowel(word) > 1 and \"(cid:141)\" not in word:\n",
        "                continue  # Удаляем этот paragraph, не добавляем его в новый документ\n",
        "\n",
        "        i = 0\n",
        "        while i < len(words):\n",
        "            word = words[i]\n",
        "\n",
        "            # Проверка, если слово после \"см.\"\n",
        "            if i > 0 and words[i-1].lower() == \"см.\" and is_cyrillic(word):\n",
        "                # Добавляем слово в текущий definition\n",
        "                if collecting_definition and current_entry is not None:\n",
        "                    definition_elem = current_entry.find(\"definition\")\n",
        "                    if definition_elem.text:\n",
        "                        definition_elem.text += \" \" + word\n",
        "                    else:\n",
        "                        definition_elem.text = word\n",
        "                i += 1\n",
        "                continue\n",
        "\n",
        "            if is_cyrillic(word) and contains_vowel(word):  # Нашли новое слово, которое удовлетворяет всем условиям\n",
        "                # Заканчиваем сбор предыдущего definition (если он есть)\n",
        "                collecting_definition = False\n",
        "\n",
        "                # Создаём новую запись\n",
        "                current_entry = ET.SubElement(new_root, \"entry\")\n",
        "                word_elem = ET.SubElement(current_entry, \"word\")\n",
        "                word_elem.text = word\n",
        "\n",
        "                # Создаём новый definition\n",
        "                definition_elem = ET.SubElement(current_entry, \"definition\")\n",
        "                collecting_definition = True\n",
        "\n",
        "            elif collecting_definition and current_entry is not None:\n",
        "                # Если это не новое слово, добавляем текст в текущий definition\n",
        "                definition_elem = current_entry.find(\"definition\")\n",
        "                if definition_elem.text:\n",
        "                    definition_elem.text += \" \" + word\n",
        "                else:\n",
        "                    definition_elem.text = word\n",
        "\n",
        "            i += 1\n",
        "\n",
        "    new_tree = ET.ElementTree(new_root)\n",
        "    new_tree.write(output_file, encoding=\"utf-8\", xml_declaration=True)\n",
        "\n",
        "# Входной и выходной файлы\n",
        "input_file = 'Glinkina_Etimologicheskie_tayni_russkoy_orfografii.xml'\n",
        "output_file = 'processed_Glinkina.xml'\n",
        "\n",
        "# Запуск обработки\n",
        "process_xml(input_file, output_file)"
      ],
      "metadata": {
        "id": "r_stD2GDl4Iy"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}