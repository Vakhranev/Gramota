{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPYR8SADr3ckwqSK4M0s/EH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vakhranev/Gramota/blob/main/%D0%A1%D0%BB%D0%BE%D0%B2%D0%B0%D1%80%D0%B8%20%D0%B2%20XML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmjZHZZUOT_2"
      },
      "outputs": [],
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import re\n",
        "\n",
        "# Список сокращений\n",
        "abbreviations = set([\n",
        "    \"адыг.\", \"америк.\", \"англ.\", \"арабск.\", \"арамейск.\", \"ассир.\", \"атт.\", \"баскск.\", \"библ.\",\n",
        "    \"болг.\", \"букв.\", \"валлийск.\", \"венг.\", \"вост.\", \"в-т\", \"галльск.\", \"гаек.\", \"гаэльск.\", \"герм.\",\n",
        "    \"гот.\", \"греч.\", \"груз.\", \"дагест.\", \"дат.\", \"диал.\", \"др.\", \"евр.\", \"егип.\", \"ж.\", \"зап.\", \"им.\",\n",
        "    \"ирл.\", \"исл.\", \"исп.\", \"ит.\", \"кавк.\", \"карфагенск.\", \"кельт.\", \"коптск.\", \"корейск.\", \"коре.\",\n",
        "    \"кумык.\", \"ласк.\", \"лат.\", \"лит.\", \"м.\", \"марийск.\", \"н.\", \"нар.\", \"нем.\", \"нидерл.\", \"нов.\",\n",
        "    \"норв.\", \"норм.\", \"орф.\", \"осет.\", \"перс.\", \"пожелат.\", \"половецк.\", \"польск.\", \"порт.\", \"прил.\",\n",
        "    \"прованс.\", \"разг.\", \"римск.\", \"румынск.\", \"рус.\", \"савойск.\", \"санскр.\", \"сербск.\", \"сирийск.\",\n",
        "    \"сканд.\", \"слав.\", \"см.\", \"сокр.\", \"ср.\", \"стар.\", \"тат.\", \"традиц.\", \"тур.\", \"тюрк.\", \"укр.\",\n",
        "    \"уменьш.\", \"усеч.\", \"ф.\", \"финск.\", \"флам.\", \"фракийск.\", \"фр.\", \"фриз.\", \"халдейск.\", \"церк.\",\n",
        "    \"цыг.\", \"чешек.\", \"швед.\", \"шотл.\", \"эльз.\", \"эолийск.\", \"др.-евр.\"\n",
        "])\n",
        "\n",
        "# Функция обработки XML\n",
        "def process_xml(input_file, output_file):\n",
        "    tree = ET.parse(input_file)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    page_number = 1\n",
        "    new_pages = []\n",
        "\n",
        "    for page in root.findall('.//page'):\n",
        "        new_page = ET.Element('page', {'number': str(page_number)})\n",
        "        page_number += 1\n",
        "\n",
        "        paragraphs = [p.text.strip() for p in page.findall('.//paragraph') if p.text]\n",
        "        text = \" \".join(paragraphs)\n",
        "\n",
        "        if text == \"ЖЕНСКИЕ ИМЕНА\":\n",
        "            new_page.append(ET.Element('female_names'))\n",
        "            new_page[-1].text = text\n",
        "            new_pages.append(new_page)\n",
        "            continue\n",
        "        elif text == \"МУЖСКИЕ ИМЕНА\":\n",
        "            new_page.append(ET.Element('male_names'))\n",
        "            new_page[-1].text = text\n",
        "            new_pages.append(new_page)\n",
        "            continue\n",
        "\n",
        "        words = text.split()\n",
        "        i = 0\n",
        "\n",
        "        while i < len(words):\n",
        "            if words[i][0].isupper():\n",
        "                word = words[i]\n",
        "                i += 1\n",
        "\n",
        "                definition_words = []\n",
        "                open_square_brackets = 0\n",
        "                open_parentheses = 0\n",
        "\n",
        "                while i < len(words):\n",
        "                    definition_words.append(words[i])\n",
        "\n",
        "                    # Проверка на открытые скобки\n",
        "                    open_square_brackets += words[i].count('[')\n",
        "                    open_square_brackets -= words[i].count(']')\n",
        "\n",
        "                    # Если встречаем точку, проверяем завершение\n",
        "                    if words[i][-1] == '.':\n",
        "                        # Проверка на сокращения\n",
        "                        if words[i] not in abbreviations and open_square_brackets == 0 and open_parentheses == 0:\n",
        "                            # Проверка следующего слова\n",
        "                            if i + 1 < len(words) and words[i + 1][0].isupper():\n",
        "                                # Если следующее слово с большой буквы, то завершение\n",
        "                                break\n",
        "                    i += 1\n",
        "\n",
        "                # Собираем определение и добавляем его в запись\n",
        "                definition = \" \".join(definition_words).strip()\n",
        "\n",
        "                entry = ET.Element('entry')\n",
        "                word_elem = ET.SubElement(entry, 'word')\n",
        "                word_elem.text = word.rstrip(',')\n",
        "                def_elem = ET.SubElement(entry, 'definition')\n",
        "                def_elem.text = definition\n",
        "                new_page.append(entry)\n",
        "\n",
        "            i += 1\n",
        "\n",
        "        new_pages.append(new_page)\n",
        "\n",
        "    root.clear()\n",
        "    for new_page in new_pages:\n",
        "        root.append(new_page)\n",
        "\n",
        "    tree.write(output_file, encoding=\"utf-8\", xml_declaration=True)\n",
        "\n",
        "# Входной и выходной файлы\n",
        "input_file = 'Superanskaya_Slovar_russkikh_lichnykh_imyon.xml'\n",
        "output_file = 'processed_Slovar.xml'\n",
        "\n",
        "# Запуск обработки\n",
        "process_xml(input_file, output_file)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import re\n",
        "\n",
        "def is_cyrillic(word):\n",
        "    # Убираем точку в конце, если есть\n",
        "    word = word.rstrip('.')\n",
        "\n",
        "    # Проверяем, состоит ли слово из заглавных кириллических букв и (cid:141), причем оно должно быть длиннее одной буквы\n",
        "    return re.fullmatch(r'(?:[А-ЯЁ]+(?:\\(cid:141\\))?)+', word) is not None and len(word) > 1\n",
        "\n",
        "def contains_vowel(word):\n",
        "    # Проверяем, есть ли в слове хотя бы одна гласная (А, Е, Ё, И, О, У, Ы, Э, Ю, Я)\n",
        "    vowels = \"АЕЁИОУЫЭЮЯ\"\n",
        "    return sum(1 for char in word if char in vowels)\n",
        "\n",
        "def process_xml(input_file, output_file):\n",
        "    tree = ET.parse(input_file)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    new_root = ET.Element(\"document\")\n",
        "    page_number = 0\n",
        "    skip_next = False\n",
        "    current_entry = None\n",
        "    collecting_definition = False  # Флаг, показывающий, собираем ли мы текст для definition\n",
        "\n",
        "    for paragraph in root.findall(\".//paragraph\"):\n",
        "        text = paragraph.text.strip() if paragraph.text else \"\"\n",
        "\n",
        "        # Проверяем, является ли paragraph номером страницы\n",
        "        if text.isdigit():\n",
        "            page_number += 1\n",
        "            skip_next = True  # Устанавливаем флаг, чтобы пропустить следующий paragraph\n",
        "            continue\n",
        "\n",
        "        if skip_next:\n",
        "            skip_next = False\n",
        "            continue  # Пропускаем этот paragraph\n",
        "\n",
        "        # Пропускаем параграфы, содержащие только одну букву\n",
        "        if len(text) == 1:\n",
        "            continue\n",
        "\n",
        "        words = text.split()\n",
        "\n",
        "        # Проверяем, если в paragraph только одно слово\n",
        "        if len(words) == 1:\n",
        "            word = words[0]\n",
        "\n",
        "            # Проверяем, что слово написано в верхнем регистре, без \"(cid:141)\" и с более чем одной гласной\n",
        "            if word.isupper() and contains_vowel(word) > 1 and \"(cid:141)\" not in word:\n",
        "                continue  # Удаляем этот paragraph, не добавляем его в новый документ\n",
        "\n",
        "        i = 0\n",
        "        while i < len(words):\n",
        "            word = words[i]\n",
        "\n",
        "            # Проверка, если слово после \"см.\"\n",
        "            if i > 0 and words[i-1].lower() == \"см.\" and is_cyrillic(word):\n",
        "                # Добавляем слово в текущий definition\n",
        "                if collecting_definition and current_entry is not None:\n",
        "                    definition_elem = current_entry.find(\"definition\")\n",
        "                    if definition_elem.text:\n",
        "                        definition_elem.text += \" \" + word\n",
        "                    else:\n",
        "                        definition_elem.text = word\n",
        "                i += 1\n",
        "                continue\n",
        "\n",
        "            if is_cyrillic(word) and contains_vowel(word):  # Нашли новое слово, которое удовлетворяет всем условиям\n",
        "                # Заканчиваем сбор предыдущего definition (если он есть)\n",
        "                collecting_definition = False\n",
        "\n",
        "                # Создаём новую запись\n",
        "                current_entry = ET.SubElement(new_root, \"entry\")\n",
        "                word_elem = ET.SubElement(current_entry, \"word\")\n",
        "                word_elem.text = word\n",
        "\n",
        "                # Создаём новый definition\n",
        "                definition_elem = ET.SubElement(current_entry, \"definition\")\n",
        "                collecting_definition = True\n",
        "\n",
        "            elif collecting_definition and current_entry is not None:\n",
        "                # Если это не новое слово, добавляем текст в текущий definition\n",
        "                definition_elem = current_entry.find(\"definition\")\n",
        "                if definition_elem.text:\n",
        "                    definition_elem.text += \" \" + word\n",
        "                else:\n",
        "                    definition_elem.text = word\n",
        "\n",
        "            i += 1\n",
        "\n",
        "    new_tree = ET.ElementTree(new_root)\n",
        "    new_tree.write(output_file, encoding=\"utf-8\", xml_declaration=True)\n",
        "\n",
        "# Входной и выходной файлы\n",
        "input_file = 'Glinkina_Etimologicheskie_tayni_russkoy_orfografii.xml'\n",
        "output_file = 'processed_Glinkina.xml'\n",
        "\n",
        "# Запуск обработки\n",
        "process_xml(input_file, output_file)"
      ],
      "metadata": {
        "id": "r_stD2GDl4Iy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import re\n",
        "\n",
        "def process_xml(input_file, output_file):\n",
        "    tree = ET.parse(input_file)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    new_root = ET.Element(\"document\")\n",
        "    page_number = 0\n",
        "    paragraphs = list(root.findall(\".//paragraph\"))\n",
        "\n",
        "    # Фильтруем параграфы: удаляем номера страниц и одиночные буквы\n",
        "    filtered_paragraphs = []\n",
        "    for para in paragraphs:\n",
        "        text = para.text.strip()\n",
        "        if text.isdigit():\n",
        "            page_number += 1\n",
        "            continue\n",
        "        if len(text) == 1 and text.isalpha():\n",
        "            continue\n",
        "        filtered_paragraphs.append(text)\n",
        "\n",
        "    # Объединяем параграфы, если предыдущий не заканчивается на точку\n",
        "    merged_paragraphs = []\n",
        "    buffer = \"\"\n",
        "    for text in filtered_paragraphs:\n",
        "        if buffer and not buffer.endswith(\".\"):\n",
        "            buffer += \" \" + text\n",
        "        else:\n",
        "            if buffer:\n",
        "                merged_paragraphs.append(buffer)\n",
        "            buffer = text\n",
        "    if buffer:\n",
        "        merged_paragraphs.append(buffer)\n",
        "\n",
        "    i = 0\n",
        "    current_definition_text = \"\"  # Для хранения текста определения\n",
        "    word_text = \"\"  # Для хранения текста слова\n",
        "\n",
        "    while i < len(merged_paragraphs):\n",
        "        text = merged_paragraphs[i]\n",
        "\n",
        "        # Регулярка: слово из заглавных букв (включая \"(cid:1)\"), оканчивающееся запятой, точкой с запятой или запятой и цифрой\n",
        "        match = re.search(r\"^([А-ЯЁ\\(cid:1\\)]+[,;]\\d*)\", text)\n",
        "\n",
        "        if match:\n",
        "            if current_definition_text:\n",
        "                entry = ET.Element(\"entry\")\n",
        "                word_elem = ET.SubElement(entry, \"word\")\n",
        "                word_elem.text = word_text.strip()\n",
        "\n",
        "                if (current_definition_text.strip().split() and word_text.strip().split() and\n",
        "    word_text.strip().split()[-1] == current_definition_text.strip().split()[-1]):\n",
        "                    definition_elem = ET.SubElement(entry, \"definition\")\n",
        "                    definition_elem.text = \"\"\n",
        "                else:\n",
        "                    definition_elem = ET.SubElement(entry, \"definition\")\n",
        "                    definition_elem.text = current_definition_text.strip()\n",
        "\n",
        "                new_root.append(entry)\n",
        "\n",
        "            word_text = match.group(1).strip()\n",
        "            match_full = re.search(r\"^([А-ЯЁ\\(cid:1\\) ,.;-]+)\", text)\n",
        "            if match_full:\n",
        "                word_text = match_full.group(1).strip()\n",
        "\n",
        "            current_definition_text = text[len(word_text):].strip()\n",
        "\n",
        "            while True:\n",
        "                match_end = re.search(r\"\\.([ \\t\\n])\", current_definition_text)\n",
        "                if match_end:\n",
        "                    if current_definition_text[match_end.end():match_end.end() + 1] == \";\":\n",
        "                        current_definition_text = current_definition_text[match_end.end():]\n",
        "                        continue\n",
        "\n",
        "                    if current_definition_text[:match_end.start()].endswith(\"мн\"):\n",
        "                        word_text += current_definition_text[:match_end.end()]\n",
        "                        current_definition_text = current_definition_text[match_end.end():]\n",
        "                        continue\n",
        "\n",
        "                    next_word = current_definition_text[match_end.end():].strip().split()[0]\n",
        "                    if next_word[0].islower() or next_word[0].startswith(\"(\"):\n",
        "                        word_text += current_definition_text[:match_end.end()]\n",
        "                        current_definition_text = current_definition_text[match_end.end():]\n",
        "                        continue\n",
        "\n",
        "                    word_text += current_definition_text[:match_end.end()]\n",
        "                    current_definition_text = current_definition_text[match_end.end():].strip()\n",
        "                    break\n",
        "                else:\n",
        "                    word_text += current_definition_text.strip()\n",
        "                    break\n",
        "        else:\n",
        "            current_definition_text += \" \" + text.strip()\n",
        "\n",
        "        i += 1\n",
        "\n",
        "    if current_definition_text:\n",
        "        entry = ET.Element(\"entry\")\n",
        "        word_elem = ET.SubElement(entry, \"word\")\n",
        "        word_elem.text = word_text.strip()\n",
        "\n",
        "        if current_definition_text.strip().split() and word_text.strip().split()[-1] == current_definition_text.strip().split()[-1]:\n",
        "            definition_elem = ET.SubElement(entry, \"definition\")\n",
        "            definition_elem.text = \"\"\n",
        "        else:\n",
        "            definition_elem = ET.SubElement(entry, \"definition\")\n",
        "            definition_elem.text = current_definition_text.strip()\n",
        "\n",
        "        new_root.append(entry)\n",
        "\n",
        "    new_tree = ET.ElementTree(new_root)\n",
        "    new_tree.write(output_file, encoding=\"utf-8\", xml_declaration=True)\n",
        "\n",
        "input_file = \"Rakhmanova_Trudnosti_russkogo_yazyka.xml\"\n",
        "output_file = \"processed_Rakhmanova.xml\"\n",
        "process_xml(input_file, output_file)"
      ],
      "metadata": {
        "id": "NhywluzxFSk6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import re\n",
        "\n",
        "def remove_spaces_after_commas(input_file):\n",
        "    # Загружаем XML\n",
        "    tree = ET.parse(input_file)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    # Ищем все параграфы в документе\n",
        "    paragraphs = root.findall(\".//paragraph\")\n",
        "\n",
        "    for paragraph in paragraphs:\n",
        "        text = paragraph.text.strip()\n",
        "\n",
        "        # Убираем пробелы после запятой\n",
        "        text = re.sub(r\",\\s+\", \",\", text)\n",
        "\n",
        "        # Обновляем текст параграфа\n",
        "        paragraph.text = text\n",
        "\n",
        "    # Сохраняем изменённый XML\n",
        "    tree.write(input_file, encoding=\"utf-8\", xml_declaration=True)\n",
        "\n",
        "# Указываем путь к исходному файлу\n",
        "input_file = \"Shelyakin_Obyasnitelnyi_slovar_neproveryayemykh_orphogramm_russkogo_yazyka.xml\"\n",
        "remove_spaces_after_commas(input_file)"
      ],
      "metadata": {
        "id": "iIzVA5hPOow1"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import re\n",
        "\n",
        "def process_xml(input_file, output_file):\n",
        "    tree = ET.parse(input_file)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    new_root = ET.Element(\"document\")\n",
        "    paragraphs = list(root.findall(\".//paragraph\"))\n",
        "\n",
        "    # Регулярное выражение для захвата слова с запятой\n",
        "    word_pattern = re.compile(r\"(-)*[A-ZА-ЯЁÁÉÓÍÚÝÄÖÜÑČŠŽ^]+([\\/\\s,A-ZА-ЯЁÁÉÓÍÚÝÄÖÜÑČŠŽ^-])*\")\n",
        "\n",
        "    entries = []\n",
        "    definition_text = \"\"\n",
        "    inside_parentheses = False\n",
        "\n",
        "    for i in range(len(paragraphs)):\n",
        "        paragraph = paragraphs[i]\n",
        "        text = paragraph.text.strip()\n",
        "\n",
        "        if len(text.split()) == 1 and text.isupper():\n",
        "            continue\n",
        "\n",
        "        if text.isdigit() or (len(text) == 1 and text.isalpha()):\n",
        "            continue\n",
        "\n",
        "        if i > 0 and paragraphs[i - 1].text.strip().isdigit():\n",
        "            next_paragraph_text = text.strip()\n",
        "            words_in_next_paragraph = next_paragraph_text.split()\n",
        "\n",
        "            if len(words_in_next_paragraph) >= 2 and all(word.isupper() for word in words_in_next_paragraph[:2]):\n",
        "                words_in_next_paragraph.pop(0)\n",
        "                text = ' '.join(words_in_next_paragraph)\n",
        "                paragraph.text = text\n",
        "\n",
        "        buffer = \"\"\n",
        "        for char in text:\n",
        "            if char.isspace():\n",
        "                if buffer:\n",
        "                    if '(' in buffer:\n",
        "                        inside_parentheses = True\n",
        "\n",
        "                    if inside_parentheses:\n",
        "                        definition_text += \" \" + buffer\n",
        "                    elif word_pattern.fullmatch(buffer):\n",
        "                        if entries:\n",
        "                            entries[-1][\"definition\"] += \" \" + definition_text.strip()\n",
        "                        definition_text = \"\"\n",
        "                        entries.append({\"word\": buffer, \"definition\": \"\"})\n",
        "                    else:\n",
        "                        definition_text += \" \" + buffer\n",
        "\n",
        "                    if ')' in buffer:\n",
        "                        inside_parentheses = False\n",
        "                    buffer = \"\"\n",
        "            else:\n",
        "                buffer += char\n",
        "\n",
        "        if buffer:\n",
        "            if '(' in buffer:\n",
        "                inside_parentheses = True\n",
        "\n",
        "            if inside_parentheses:\n",
        "                definition_text += \" \" + buffer\n",
        "            elif word_pattern.fullmatch(buffer):\n",
        "                if entries:\n",
        "                    entries[-1][\"definition\"] += \" \" + definition_text.strip()\n",
        "                definition_text = \"\"\n",
        "                entries.append({\"word\": buffer, \"definition\": \"\"})\n",
        "            else:\n",
        "                definition_text += \" \" + buffer\n",
        "\n",
        "            if ')' in buffer:\n",
        "                inside_parentheses = False\n",
        "\n",
        "    if definition_text and entries:\n",
        "        entries[-1][\"definition\"] += \" \" + definition_text.strip()\n",
        "\n",
        "    # Выводим данные в новый XML\n",
        "    for entry in entries:\n",
        "        entry_elem = ET.Element(\"entry\")\n",
        "        word_elem = ET.SubElement(entry_elem, \"word\")\n",
        "        word_elem.text = entry[\"word\"]\n",
        "        definition_elem = ET.SubElement(entry_elem, \"definition\")\n",
        "        definition_elem.text = entry[\"definition\"].strip()\n",
        "        new_root.append(entry_elem)\n",
        "\n",
        "    new_tree = ET.ElementTree(new_root)\n",
        "    new_tree.write(output_file, encoding=\"utf-8\", xml_declaration=True)\n",
        "\n",
        "input_file = \"Shelyakin_Obyasnitelnyi_slovar_neproveryayemykh_orphogramm_russkogo_yazyka.xml\"\n",
        "output_file = \"processed_Shelyakin.xml\"\n",
        "process_xml(input_file, output_file)"
      ],
      "metadata": {
        "id": "n-crbafk73sj"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import re\n",
        "\n",
        "def add_spaces_after_commas(input_file):\n",
        "    # Загружаем XML\n",
        "    tree = ET.parse(input_file)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    # Ищем все параграфы в документе\n",
        "    paragraphs = root.findall(\".//paragraph\")\n",
        "\n",
        "    for paragraph in paragraphs:\n",
        "        text = paragraph.text.strip()\n",
        "\n",
        "        # Добавляем пробел после каждой запятой, если его нет\n",
        "        text = re.sub(r\",(?!\\s)\", \", \", text)\n",
        "\n",
        "        # Обновляем текст параграфа\n",
        "        paragraph.text = text\n",
        "\n",
        "    # Сохраняем изменённый XML\n",
        "    tree.write(input_file, encoding=\"utf-8\", xml_declaration=True)\n",
        "\n",
        "# Указываем путь к файлу\n",
        "input_file = \"processed_Shelyakin.xml\"\n",
        "add_spaces_after_commas(input_file)"
      ],
      "metadata": {
        "id": "T87nHA62Txkt"
      },
      "execution_count": 37,
      "outputs": []
    }
  ]
}